<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Interface IChatEndpoint
   </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Interface IChatEndpoint
   ">
    <meta name="generator" content="docfx 2.59.4.0">
    
    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src="../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="OpenAI_API.Chat.IChatEndpoint">
  
  
  <h1 id="OpenAI_API_Chat_IChatEndpoint" data-uid="OpenAI_API.Chat.IChatEndpoint" class="text-break">Interface IChatEndpoint
  </h1>
  <div class="markdown level0 summary"><p>An interface for <a class="xref" href="OpenAI_API.Chat.ChatEndpoint.html">ChatEndpoint</a>, the ChatGPT API endpoint. Use this endpoint to send multiple messages and carry on a conversation.</p>
</div>
  <div class="markdown level0 conceptual"></div>
  <h6><strong>Namespace</strong>: <a class="xref" href="OpenAI_API.Chat.html">OpenAI_API.Chat</a></h6>
  <h6><strong>Assembly</strong>: Assembly-CSharp.dll</h6>
  <h5 id="OpenAI_API_Chat_IChatEndpoint_syntax">Syntax</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public interface IChatEndpoint</code></pre>
  </div>
  <h3 id="properties">Properties
  </h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.DefaultChatRequestArgs%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L16">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs_" data-uid="OpenAI_API.Chat.IChatEndpoint.DefaultChatRequestArgs*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs" data-uid="OpenAI_API.Chat.IChatEndpoint.DefaultChatRequestArgs">DefaultChatRequestArgs</h4>
  <div class="markdown level1 summary"><p>This allows you to set default parameters for every request, for example to set a default temperature or max tokens.  For every request, if you do not have a parameter set on the request but do have it set here as a default, the request will automatically pick up the default value.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">ChatRequest DefaultChatRequestArgs { get; set; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatRequest.html">ChatRequest</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h3 id="methods">Methods
  </h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_OpenAI_API_Chat_ChatMessage___.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(OpenAI_API.Chat.ChatMessage%5B%5D)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L62">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_OpenAI_API_Chat_ChatMessage___" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(OpenAI_API.Chat.ChatMessage[])">CreateChatCompletionAsync(ChatMessage[])</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the request using the specified message(s).  Any parameters will fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a> if present.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task&lt;ChatResult&gt; CreateChatCompletionAsync(params ChatMessage[] messages)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatMessage.html">ChatMessage</a>[]</td>
        <td><span class="parametername">messages</span></td>
        <td><p>The messages to use in the generation.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>The <a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a> with the API response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_OpenAI_API_Chat_ChatRequest_.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(OpenAI_API.Chat.ChatRequest)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L31">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_OpenAI_API_Chat_ChatRequest_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(OpenAI_API.Chat.ChatRequest)">CreateChatCompletionAsync(ChatRequest)</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the request using the specified parameters. This is non-streaming, so it will wait until the API returns the full result. Any non-specified parameters will fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a> if present.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task&lt;ChatResult&gt; CreateChatCompletionAsync(ChatRequest request)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatRequest.html">ChatRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request to send to the API.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>Asynchronously returns the completion result. Look in its <a class="xref" href="OpenAI_API.Chat.ChatResult.html#OpenAI_API_Chat_ChatResult_Choices">Choices</a> property for the results.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_OpenAI_API_Chat_ChatRequest_System_Int32_.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(OpenAI_API.Chat.ChatRequest%2CSystem.Int32)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L39">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_OpenAI_API_Chat_ChatRequest_System_Int32_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(OpenAI_API.Chat.ChatRequest,System.Int32)">CreateChatCompletionAsync(ChatRequest, Int32)</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the request using the specified parameters. This is non-streaming, so it will wait until the API returns the full result. Any non-specified parameters will fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a> if present.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task&lt;ChatResult&gt; CreateChatCompletionAsync(ChatRequest request, int numOutputs = 5)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatRequest.html">ChatRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request to send to the API.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Int32</span></td>
        <td><span class="parametername">numOutputs</span></td>
        <td><p>Overrides <a class="xref" href="OpenAI_API.Chat.ChatRequest.html#OpenAI_API_Chat_ChatRequest_NumChoicesPerMessage">NumChoicesPerMessage</a> as a convenience.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>Asynchronously returns the completion result. Look in its <a class="xref" href="OpenAI_API.Chat.ChatResult.html#OpenAI_API_Chat_ChatResult_Choices">Choices</a> property for the results.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_System_Collections_Generic_IList_OpenAI_API_Chat_ChatMessage__OpenAI_API_Models_Model_System_Nullable_System_Double__System_Nullable_System_Double__System_Nullable_System_Int32__System_Nullable_System_Int32__System_Nullable_System_Double__System_Nullable_System_Double__System_Collections_Generic_IReadOnlyDictionary_System_String_System_Single__System_String___.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(System.Collections.Generic.IList%7BOpenAI_API.Chat.ChatMessage%7D%2COpenAI_API.Models.Model%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Nullable%7BSystem.Int32%7D%2CSystem.Nullable%7BSystem.Int32%7D%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Collections.Generic.IReadOnlyDictionary%7BSystem.String%2CSystem.Single%7D%2CSystem.String%5B%5D)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L55">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_System_Collections_Generic_IList_OpenAI_API_Chat_ChatMessage__OpenAI_API_Models_Model_System_Nullable_System_Double__System_Nullable_System_Double__System_Nullable_System_Int32__System_Nullable_System_Int32__System_Nullable_System_Double__System_Nullable_System_Double__System_Collections_Generic_IReadOnlyDictionary_System_String_System_Single__System_String___" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(System.Collections.Generic.IList{OpenAI_API.Chat.ChatMessage},OpenAI_API.Models.Model,System.Nullable{System.Double},System.Nullable{System.Double},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Double},System.Nullable{System.Double},System.Collections.Generic.IReadOnlyDictionary{System.String,System.Single},System.String[])">CreateChatCompletionAsync(IList&lt;ChatMessage&gt;, Model, Nullable&lt;Double&gt;, Nullable&lt;Double&gt;, Nullable&lt;Int32&gt;, Nullable&lt;Int32&gt;, Nullable&lt;Double&gt;, Nullable&lt;Double&gt;, IReadOnlyDictionary&lt;String, Single&gt;, String[])</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the request using the specified parameters. This is non-streaming, so it will wait until the API returns the full result. Any non-specified parameters will fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a> if present.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task&lt;ChatResult&gt; CreateChatCompletionAsync(IList&lt;ChatMessage&gt; messages, Model model = null, double? temperature = null, double? top_p = null, int? numOutputs = null, int? max_tokens = null, double? frequencyPenalty = null, double? presencePenalty = null, IReadOnlyDictionary&lt;string, float&gt; logitBias = null, params string[] stopSequences)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Collections.Generic.IList</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatMessage.html">ChatMessage</a>&gt;</td>
        <td><span class="parametername">messages</span></td>
        <td><p>The array of messages to send to the API</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="OpenAI_API.Models.Model.html">Model</a></td>
        <td><span class="parametername">model</span></td>
        <td><p>The model to use. See the ChatGPT models available from <a class="xref" href="OpenAI_API.Models.ModelsEndpoint.html#OpenAI_API_Models_ModelsEndpoint_GetModelsAsync">GetModelsAsync()</a></p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">temperature</span></td>
        <td><p>What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer. It is generally recommend to use this or <code data-dev-comment-type="paramref" class="paramref">top_p</code> but not both.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">top_p</span></td>
        <td><p>An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommend to use this or <code data-dev-comment-type="paramref" class="paramref">temperature</code> but not both.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Int32</span>&gt;</td>
        <td><span class="parametername">numOutputs</span></td>
        <td><p>How many different choices to request for each prompt.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Int32</span>&gt;</td>
        <td><span class="parametername">max_tokens</span></td>
        <td><p>How many tokens to complete to. Can return fewer if a stop sequence is hit.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">frequencyPenalty</span></td>
        <td><p>The scale of the penalty for how often a token is used.  Should generally be between 0 and 1, although negative numbers are allowed to encourage token reuse.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">presencePenalty</span></td>
        <td><p>The scale of the penalty applied if a token is already present at all.  Should generally be between 0 and 1, although negative numbers are allowed to encourage token reuse.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Collections.Generic.IReadOnlyDictionary</span>&lt;<span class="xref">System.String</span>, <span class="xref">System.Single</span>&gt;</td>
        <td><span class="parametername">logitBias</span></td>
        <td><p>Maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.String</span>[]</td>
        <td><span class="parametername">stopSequences</span></td>
        <td><p>One or more sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>Asynchronously returns the completion result. Look in its <a class="xref" href="OpenAI_API.Chat.ChatResult.html#OpenAI_API_Chat_ChatResult_Choices">Choices</a> property for the results.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_System_String_OpenAI_API_Chat_ChatMessage_ImageInput___.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(System.String%2COpenAI_API.Chat.ChatMessage.ImageInput%5B%5D)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L77">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_System_String_OpenAI_API_Chat_ChatMessage_ImageInput___" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(System.String,OpenAI_API.Chat.ChatMessage.ImageInput[])">CreateChatCompletionAsync(String, ChatMessage.ImageInput[])</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the request using the specified message and image(s).  Any parameters will fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a> if present, except for <a class="xref" href="OpenAI_API.Chat.ChatRequest.html#OpenAI_API_Chat_ChatRequest_Model">Model</a>, which will default to <a class="xref" href="OpenAI_API.Models.Model.html#OpenAI_API_Models_Model_GPT4_Vision">GPT4_Vision</a>.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task&lt;ChatResult&gt; CreateChatCompletionAsync(string userMessage, params ChatMessage.ImageInput[] images)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.String</span></td>
        <td><span class="parametername">userMessage</span></td>
        <td><p>The user message text to use in the generation.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatMessage.ImageInput.html">ChatMessage.ImageInput</a>[]</td>
        <td><span class="parametername">images</span></td>
        <td><p>The images to use in the generation.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>The <a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a> with the API response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_System_String___.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(System.String%5B%5D)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L69">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_CreateChatCompletionAsync_System_String___" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateChatCompletionAsync(System.String[])">CreateChatCompletionAsync(String[])</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the request using the specified message(s).  Any parameters will fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a> if present.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task&lt;ChatResult&gt; CreateChatCompletionAsync(params string[] userMessages)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.String</span>[]</td>
        <td><span class="parametername">userMessages</span></td>
        <td><p>The user message or messages to use in the generation.  All strings are assumed to be of Role <a class="xref" href="OpenAI_API.Chat.ChatMessageRole.html#OpenAI_API_Chat_ChatMessageRole_User">User</a></p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>The <a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a> with the API response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_CreateConversation_OpenAI_API_Chat_ChatRequest_.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.CreateConversation(OpenAI_API.Chat.ChatRequest)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L23">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_CreateConversation_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateConversation*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_CreateConversation_OpenAI_API_Chat_ChatRequest_" data-uid="OpenAI_API.Chat.IChatEndpoint.CreateConversation(OpenAI_API.Chat.ChatRequest)">CreateConversation(ChatRequest)</h4>
  <div class="markdown level1 summary"><p>Creates an ongoing chat which can easily encapsulate the conversation.  This is the simplest way to use the Chat endpoint.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Conversation CreateConversation(ChatRequest defaultChatRequestArgs = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatRequest.html">ChatRequest</a></td>
        <td><span class="parametername">defaultChatRequestArgs</span></td>
        <td><p>Allows setting the parameters to use when calling the ChatGPT API.  Can be useful for setting temperature, presence_penalty, and more.  See <a href="https://platform.openai.com/docs/api-reference/chat/create">OpenAI documentation for a list of possible parameters to tweak.</a></p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.Conversation.html">Conversation</a></td>
        <td><p>A <a class="xref" href="OpenAI_API.Chat.Conversation.html">Conversation</a> which encapsulates a back and forth chat between a user and an assistant.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_StreamChatAsync_OpenAI_API_Chat_ChatRequest_System_Action_OpenAI_API_Chat_ChatResult__.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.StreamChatAsync(OpenAI_API.Chat.ChatRequest%2CSystem.Action%7BOpenAI_API.Chat.ChatResult%7D)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L86">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_StreamChatAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamChatAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_StreamChatAsync_OpenAI_API_Chat_ChatRequest_System_Action_OpenAI_API_Chat_ChatResult__" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamChatAsync(OpenAI_API.Chat.ChatRequest,System.Action{OpenAI_API.Chat.ChatResult})">StreamChatAsync(ChatRequest, Action&lt;ChatResult&gt;)</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the message(s) using the specified request, and stream the results to the <code data-dev-comment-type="paramref" class="paramref">resultHandler</code> as they come in.
If you are on the latest C# supporting async enumerables, you may prefer the cleaner syntax of <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_OpenAI_API_Chat_ChatRequest_">StreamChatEnumerableAsync(ChatRequest)</a> instead.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task StreamChatAsync(ChatRequest request, Action&lt;ChatResult&gt; resultHandler)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatRequest.html">ChatRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request to send to the API. This does not fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a>.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Action</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><span class="parametername">resultHandler</span></td>
        <td><p>An action to be called as each new result arrives, which includes the index of the result in the overall result set.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_OpenAI_API_Chat_ChatRequest_.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.StreamChatEnumerableAsync(OpenAI_API.Chat.ChatRequest)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L94">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamChatEnumerableAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_OpenAI_API_Chat_ChatRequest_" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamChatEnumerableAsync(OpenAI_API.Chat.ChatRequest)">StreamChatEnumerableAsync(ChatRequest)</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the message(s) using the specified request, and stream the results as they come in.
If you are not using C# 8 supporting async enumerables or if you are using the .NET Framework, you may need to use <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_StreamChatAsync_OpenAI_API_Chat_ChatRequest_System_Action_OpenAI_API_Chat_ChatResult__">StreamChatAsync(ChatRequest, Action&lt;ChatResult&gt;)</a> instead.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">IAsyncEnumerable&lt;ChatResult&gt; StreamChatEnumerableAsync(ChatRequest request)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatRequest.html">ChatRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request to send to the API.  This does not fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a>.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Collections.Generic.IAsyncEnumerable</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>An async enumerable with each of the results as they come in.  See <a href="https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-8#asynchronous-streams">https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-8#asynchronous-streams</a> for more details on how to consume an async enumerable.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_System_Collections_Generic_IList_OpenAI_API_Chat_ChatMessage__OpenAI_API_Models_Model_System_Nullable_System_Double__System_Nullable_System_Double__System_Nullable_System_Int32__System_Nullable_System_Int32__System_Nullable_System_Double__System_Nullable_System_Double__System_Collections_Generic_IReadOnlyDictionary_System_String_System_Single__System_String___.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.StreamChatEnumerableAsync(System.Collections.Generic.IList%7BOpenAI_API.Chat.ChatMessage%7D%2COpenAI_API.Models.Model%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Nullable%7BSystem.Int32%7D%2CSystem.Nullable%7BSystem.Int32%7D%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Nullable%7BSystem.Double%7D%2CSystem.Collections.Generic.IReadOnlyDictionary%7BSystem.String%2CSystem.Single%7D%2CSystem.String%5B%5D)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L111">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamChatEnumerableAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_System_Collections_Generic_IList_OpenAI_API_Chat_ChatMessage__OpenAI_API_Models_Model_System_Nullable_System_Double__System_Nullable_System_Double__System_Nullable_System_Int32__System_Nullable_System_Int32__System_Nullable_System_Double__System_Nullable_System_Double__System_Collections_Generic_IReadOnlyDictionary_System_String_System_Single__System_String___" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamChatEnumerableAsync(System.Collections.Generic.IList{OpenAI_API.Chat.ChatMessage},OpenAI_API.Models.Model,System.Nullable{System.Double},System.Nullable{System.Double},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Double},System.Nullable{System.Double},System.Collections.Generic.IReadOnlyDictionary{System.String,System.Single},System.String[])">StreamChatEnumerableAsync(IList&lt;ChatMessage&gt;, Model, Nullable&lt;Double&gt;, Nullable&lt;Double&gt;, Nullable&lt;Int32&gt;, Nullable&lt;Int32&gt;, Nullable&lt;Double&gt;, Nullable&lt;Double&gt;, IReadOnlyDictionary&lt;String, Single&gt;, String[])</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the message(s) using the specified request, and stream the results as they come in.
If you are not using C# 8 supporting async enumerables or if you are using the .NET Framework, you may need to use <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_StreamChatAsync_OpenAI_API_Chat_ChatRequest_System_Action_OpenAI_API_Chat_ChatResult__">StreamChatAsync(ChatRequest, Action&lt;ChatResult&gt;)</a> instead.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">IAsyncEnumerable&lt;ChatResult&gt; StreamChatEnumerableAsync(IList&lt;ChatMessage&gt; messages, Model model = null, double? temperature = null, double? top_p = null, int? numOutputs = null, int? max_tokens = null, double? frequencyPenalty = null, double? presencePenalty = null, IReadOnlyDictionary&lt;string, float&gt; logitBias = null, params string[] stopSequences)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Collections.Generic.IList</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatMessage.html">ChatMessage</a>&gt;</td>
        <td><span class="parametername">messages</span></td>
        <td><p>The array of messages to send to the API</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="OpenAI_API.Models.Model.html">Model</a></td>
        <td><span class="parametername">model</span></td>
        <td><p>The model to use. See the ChatGPT models available from <a class="xref" href="OpenAI_API.Models.ModelsEndpoint.html#OpenAI_API_Models_ModelsEndpoint_GetModelsAsync">GetModelsAsync()</a></p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">temperature</span></td>
        <td><p>What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer. It is generally recommend to use this or <code data-dev-comment-type="paramref" class="paramref">top_p</code> but not both.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">top_p</span></td>
        <td><p>An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommend to use this or <code data-dev-comment-type="paramref" class="paramref">temperature</code> but not both.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Int32</span>&gt;</td>
        <td><span class="parametername">numOutputs</span></td>
        <td><p>How many different choices to request for each prompt.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Int32</span>&gt;</td>
        <td><span class="parametername">max_tokens</span></td>
        <td><p>How many tokens to complete to. Can return fewer if a stop sequence is hit.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">frequencyPenalty</span></td>
        <td><p>The scale of the penalty for how often a token is used.  Should generally be between 0 and 1, although negative numbers are allowed to encourage token reuse.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Nullable</span>&lt;<span class="xref">System.Double</span>&gt;</td>
        <td><span class="parametername">presencePenalty</span></td>
        <td><p>The scale of the penalty applied if a token is already present at all.  Should generally be between 0 and 1, although negative numbers are allowed to encourage token reuse.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Collections.Generic.IReadOnlyDictionary</span>&lt;<span class="xref">System.String</span>, <span class="xref">System.Single</span>&gt;</td>
        <td><span class="parametername">logitBias</span></td>
        <td><p>Maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.String</span>[]</td>
        <td><span class="parametername">stopSequences</span></td>
        <td><p>One or more sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Collections.Generic.IAsyncEnumerable</span>&lt;<a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><p>An async enumerable with each of the results as they come in. See <a href="https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-8#asynchronous-streams">the C# docs</a> for more details on how to consume an async enumerable.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint_StreamCompletionAsync_OpenAI_API_Chat_ChatRequest_System_Action_System_Int32_OpenAI_API_Chat_ChatResult__.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint.StreamCompletionAsync(OpenAI_API.Chat.ChatRequest%2CSystem.Action%7BSystem.Int32%2COpenAI_API.Chat.ChatResult%7D)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L119">View Source</a>
  </span>
  <a id="OpenAI_API_Chat_IChatEndpoint_StreamCompletionAsync_" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamCompletionAsync*"></a>
  <h4 id="OpenAI_API_Chat_IChatEndpoint_StreamCompletionAsync_OpenAI_API_Chat_ChatRequest_System_Action_System_Int32_OpenAI_API_Chat_ChatResult__" data-uid="OpenAI_API.Chat.IChatEndpoint.StreamCompletionAsync(OpenAI_API.Chat.ChatRequest,System.Action{System.Int32,OpenAI_API.Chat.ChatResult})">StreamCompletionAsync(ChatRequest, Action&lt;Int32, ChatResult&gt;)</h4>
  <div class="markdown level1 summary"><p>Ask the API to complete the message(s) using the specified request, and stream the results to the <code data-dev-comment-type="paramref" class="paramref">resultHandler</code> as they come in.
If you are on the latest C# supporting async enumerables, you may prefer the cleaner syntax of <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_StreamChatEnumerableAsync_OpenAI_API_Chat_ChatRequest_">StreamChatEnumerableAsync(ChatRequest)</a> instead.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task StreamCompletionAsync(ChatRequest request, Action&lt;int, ChatResult&gt; resultHandler)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="OpenAI_API.Chat.ChatRequest.html">ChatRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request to send to the API. This does not fall back to default values specified in <a class="xref" href="OpenAI_API.Chat.IChatEndpoint.html#OpenAI_API_Chat_IChatEndpoint_DefaultChatRequestArgs">DefaultChatRequestArgs</a>.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Action</span>&lt;<span class="xref">System.Int32</span>, <a class="xref" href="OpenAI_API.Chat.ChatResult.html">ChatResult</a>&gt;</td>
        <td><span class="parametername">resultHandler</span></td>
        <td><p>An action to be called as each new result arrives, which includes the index of the result in the overall result set.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/248lee/PigziVSZombies/new/master/apiSpec/new?filename=OpenAI_API_Chat_IChatEndpoint.md&amp;value=---%0Auid%3A%20OpenAI_API.Chat.IChatEndpoint%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A" class="contribution-link">Improve this Doc</a>
                  </li>
                  <li>
                    <a href="https://github.com/248lee/PigziVSZombies/blob/master/Assets/OpenAI_API/Chat/IChatEndpoint.cs/#L11" class="contribution-link">View Source</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In This Article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
